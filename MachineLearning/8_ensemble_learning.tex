% !TEX root = main.tex

\section{集成学习}
集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务，通常可以获得比单一学习器更为显著的泛化性能。

同质(homogeneous)集成中的个体学习器称为基学习器(base learner)；而异质(heterogeneous)集成中的个体学习器则一般称为组件学习器(component learner)。
\begin{figure}[H]
\centering
\includegraphics[width=0.5\linewidth]{fig/ensemble-learning.png}
\end{figure}

考虑二分类问题，假设基分类器的错误率为
\[\pr{h_i(\vx)\ne f(\vx)}=\eps\]
假设集成通过简单投票法结合$T$个分类器，若有超过半数的基分类器正确则分类正确
\[H(\vx)=\mathrm{sign}\lrp{\sum_{i=1}^Th_i(\vx)}\]
假设基分类器的错误率相互独立，则由Hoeffding不等式可得集成错误率为
\[\begin{aligned}
\pr{H(\vx)\ne f(\vx)}
&=\sum_{k=0}^{\lfloor T/2\rfloor}\binom{T}{k}(1-\eps)^k\eps^{T-k}\\
&=\exp\lrp{-\frac{1}{2}T(1-2\eps)^2}
\end{aligned}\]
即在一定条件下，随着集成分类器数目的增加，集成的错误率将指数级下降，最终趋于$0$。

但上面的分析有一假设：基学习器的误差相互独立。
现实生活中个体学习器是为解决同一个问题而训练出来的，显然不可能相互独立。
个体学习器的“准确性”和“多样性”之间本来就存在冲突。
如何产生“好而不同”的个体学习器是集成学习研究的核心。

\subsection{Boosting}
提升(Boosting)可以将弱学习器提升为强学习器，后面的模型是基于前面模型的训练结果（误差），它的代表是AdaBoost。
每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化，而权值是根据上一轮的分类结果进行调整。

对目标函数$f(\vx)$进行多次逼近，通过不断拟合残差达到逼近的效果，可以按照下式不断迭代
\[\begin{aligned}
f_1(\vx) &=\widehat{f}(\vx)            & h_1(\vx) &=f(\vx)-f_1(\vx)\\
f_2(\vx) &=f_1(\vx)+\widehat{h_1}(\vx) & h_2(\vx) &=f(\vx)-f_2(\vx)\\
f_3(\vx) &=f_2(\vx)+\widehat{h_2}(\vx) & h_3(\vx) &=f(\vx)-f_3(\vx)\\
\vdots   &                             & \vdots \\
f_n(\vx) &=f_{n-1}(\vx)+\widehat{h_{n-1}}(\vx)
\end{aligned}\]

\begin{figure}[H]
\centering
\includegraphics[width=0.8\linewidth]{fig/adaboost.jpg}
\caption{AdaBoost算法}
\end{figure}

\subsection{Bagging}
Bagging是Bootstrap aggregating的缩写，用来生成多个分类器并且集成这些分类器形成一个整体模型。
Bagging[Breiman, 1996]基于\textbf{自助采样法（有放回的随机采样）}，采样出$T$个含$m$个样本的采样集$D_t$，然后基于每个采样集训练出一个基学习器$M_t$，再将这些基学习器结合。
对未知样本$X$分类，每个分类器返回类预测，将得票最高的类赋予$X$。
对于回归问题，则取每个分类器的预测值的平均值。

Bagging的时间复杂度低，与直接使用基学习器的复杂度同阶。
个体学习器不存在强依赖关系，可以并行化生成。

随机森林[Breiman, 2001]是Bagging的一个扩展变体。
传统决策树在选择划分属性时是在当前结点的属性集合（假定有$d$个属性）中选择一个最优属性；
而在随机森林中则是对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含$k$个属性的子集，然后再从这个子集中选择一个最优属性进行划分。
这里的$k$即控制了随机程度，一般用$k=\log_2 d$[Breiman, 2001]。

随机森林中采用两到三层的随机性包括：
\begin{enumerate}
	\item 随机有放回地抽取数据（使用Bagging）输入决策树模型
	\item 随机选取$m$个特征
	\item 随机选择特征取值进行分割（不遍历特征所有取值）
\end{enumerate}
注意由于建立决策树时的样本选择和特征选择所提供的随机性，因此不需要剪枝。

有两种指标衡量随机森林的表现：
\begin{itemize}
	\item 分类间隔(margin)：森林中正确样本决策树的比例减去错误样本决策树的比例。
	假设样本$A$有75\%的树分类正确，那么分类间隔就是75\%-25\%=50\%。
	通常希望分类间隔越大越好，因为大的间隔表示我们的分类效果比较稳定，泛化效果更好。
	\item 袋外错误率(out-of-bag error)：对每棵树来说，都有部分样本没有被抽样进入训练样本，这些即为袋外样本。
	随机森林对袋外样本的预测错误比率被称为袋外错误率。
\end{itemize}

\subsection{Stacking}
最简单的就是简单平均或加权平均。
另外也可以通过投票法，绝对多数(majority)投票法、相对多数(plurality)投票法和加权投票法。

当训练数据很多时，更为强大的结合策略是使用学习法，即通过另一个学习器来进行结合。
Stacking [Wolpert, 1992]是学习法的典型代表。
这里把个体学习器称为次级学习器或元学习器(meta-learner)。

Stacking先从初始数据集中训练出初级学习器，然后生成一个新数据集用于训练次级学习器。
在新数据集中，初级学习器的输出被当作\emph{样例输入特征}，而初始样本的标记仍被当作样例标记。

由于次级训练集是用初级学习器产生的，故直接用初级学习器的训练集产生次级学习器过拟合风险较大；因此常通过交叉验证或留一法，用训练初级学习器未使用的样本来产生次级学习器的训练样本。
以$k$折交叉验证为例，初始训练集$D$被随机划分为$k$个大小相似的集合$D_1,D_2,\ldots,D_k$。
令$D_j$和$\bar{D}_j=D\backslash D_j$分别表示第$j$折的测试集和训练集。
给定$T$个初级学习算法，初级学习器$h_t^{(j)}$通过在$\bar{D}_j$上使用第$t$个学习算法而得。
对于$D_j$的每个样本$\vx_i$，令$z_{it}=h_t^{(j)}(\vx_i)$，则由$\vx_i$所产生的次级训练样例的实例部分为$\vz_i=\bmat{z_{i1} & z_{i2} & \cdots & z_{iT}}$，标记部分为$y_i$。
故整个交叉验证过程结束后，从这$T$个初级学习器产生的次级训练集是$D'=\{(\vz_i,y_i\}_{i=1}^m$，然后$D'$将用于训练次级学习器。

贝叶斯模型平均(BMA)基于后验概率来为不同模型赋予权重，可视为加权平均的一种特殊实现。

多样性增强的方法：
\begin{itemize}
	\item 数据样本扰动：通常基于采样法，Bagging中的自助采样法和AdaBoost中的序列采样。
	数据样本扰动对“不稳定基学习器”很有效。
	\begin{itemize}
		\item 对数据样本扰动敏感的不稳定基学习器：决策树、神经网络
		\item 对数据样本扰动不敏感的稳定基学习器：线性学习器、支持向量机、朴素贝叶斯、$k$近邻
	\end{itemize}
	\item 输入属性扰动：随机子空间算法，基于初始属性集，抽取出若干个属性子集，然后基于每个属性子集训练一个基学习器
\end{itemize}